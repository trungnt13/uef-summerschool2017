{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image processing and classification\n",
    "### Tutors: [Juha Mehtonen, Trung Ngo Trong]()\n",
    "\n",
    "-----\n",
    "\n",
    "## Loading libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function, absolute_import, division\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.core.pylabtools import figsize\n",
    "figsize(12, 6)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "from scipy.stats import itemfreq\n",
    "import numpy as np\n",
    "np.random.seed(1208)\n",
    "\n",
    "from utils import (rotate, shift, zoom, shear, one_hot, cifar_labels,\n",
    "                   plot_hist)\n",
    "\n",
    "from keras.utils import Progbar\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
    "from keras.optimizers import RMSprop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we need for this task:\n",
    "\n",
    "* **numpy and scipy**: for loading images and matrix manipulation\n",
    "* **utils**: for some shortcuts to images transformation\n",
    "* **keras**: powerful neural network library for training the classifier\n",
    "\n",
    "## Constants\n",
    "\n",
    "Setting the amount of training, validating, and testing data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_OF_VISUALIZATION = 25\n",
    "TRAINING_PORTION = 0.5\n",
    "VALID_PORTION = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and visualize the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('MNIST_x.npy')\n",
    "y = np.load('MNIST_y.npy')\n",
    "print(\"MNIST shapes:\", x.shape, y.shape)\n",
    "\n",
    "# ====== visualize the data ====== #\n",
    "fig = plt.figure()\n",
    "labels = ''\n",
    "n = int(np.sqrt(NB_OF_VISUALIZATION))\n",
    "for i in range(NB_OF_VISUALIZATION):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    ax.axis('off')\n",
    "    # plot grey scale image require 2D array\n",
    "    plt.imshow(x[i][:, :, 0], cmap=plt.cm.Greys_r)\n",
    "    ax.set_title(\"Number: %d\" % y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What can we see from the images?\n",
    "\n",
    "* The image is grayscale, binary photos(i.e. features are 0 or 1)\n",
    "* Not much rotation or translation appeared to different images from the same digit\n",
    "* The labels are matched with the images, hence, the provided dataset is clean and sound\n",
    "\n",
    "## Augmentation images for training\n",
    "\n",
    "Since only _50 % _ of the dataset is used for training, it is good idea to perform data augmentation ?\n",
    "\n",
    "The idea of data augmentation is:\n",
    "\n",
    ">> > Increasing the amount of data by introducing noise, or transformation to original images to create a more robust dataset.\n",
    "\n",
    "There are four basic image transformation can be applied:\n",
    "\n",
    "* Rotation\n",
    "* Translation(shift)\n",
    "* Zooming\n",
    "* Shearing\n",
    "\n",
    "All are visualized by following figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(2, 4, 1)\n",
    "ax.imshow(img[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Original image')\n",
    "\n",
    "ax = plt.subplot(2, 4, 2)\n",
    "ax.imshow(rotate(img, 45)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Rotated positive')\n",
    "\n",
    "ax = plt.subplot(2, 4, 2)\n",
    "ax.imshow(rotate(img, -45)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Rotated negative')\n",
    "\n",
    "ax = plt.subplot(2, 4, 3)\n",
    "ax.imshow(shift(img, 0.2, 0.2)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Shift positive')\n",
    "\n",
    "ax = plt.subplot(2, 4, 4)\n",
    "ax.imshow(shift(img, -0.2, -0.2)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Shift negative')\n",
    "\n",
    "ax = plt.subplot(2, 4, 5)\n",
    "ax.imshow(zoom(img, 2, 2)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Zoom small')\n",
    "\n",
    "ax = plt.subplot(2, 4, 6)\n",
    "ax.imshow(zoom(img, 0.8, 0.8)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Zoom big')\n",
    "\n",
    "ax = plt.subplot(2, 4, 7)\n",
    "ax.imshow(shear(img, 0.8)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Shear negative')\n",
    "\n",
    "ax = plt.subplot(2, 4, 8)\n",
    "ax.imshow(shear(img, -0.8)[:, :, 0], cmap=plt.cm.Greys_r)\n",
    "ax.axis('off')\n",
    "ax.set_title('Shear positive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data splitting for training classifiers\n",
    "\n",
    "We are interested in the generalization ability of the model to new data, it is important to create reliable datasets for evaluating this criterion.\n",
    "\n",
    "Since the model is fitted on training set, the performance on training data is trivial.\n",
    "As a result, we split the dataset into 3 partitions:\n",
    "\n",
    "* Training set\n",
    "* Validating set: for model selection, hyper - parameters fine tuning.\n",
    "* Testing set: for final evaluation of the model, since the model has never seen those data, its performance is closest to the generalization ability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation = np.random.permutation(len(x))\n",
    "x = x[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "nb_train = int(TRAINING_PORTION * len(x))\n",
    "nb_valid = int(VALID_PORTION * len(x))\n",
    "nb_test = len(x) - nb_train - nb_valid\n",
    "\n",
    "x_train = x[:nb_train]\n",
    "y_train = y[:nb_train]\n",
    "\n",
    "x_valid = x[nb_train:nb_train + nb_valid]\n",
    "y_valid = y[nb_train:nb_train + nb_valid]\n",
    "\n",
    "x_test = x[nb_train + nb_valid:]\n",
    "y_test = y[nb_train + nb_valid:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another important note is that we only perform augmentation on training data, followed by this code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== augmenting the training data ====== #\n",
    "augment_function = [lambda img: shift(img, 0.1, -0.2),\n",
    "                    lambda img: rotate(img, 45)]\n",
    "# apply on out data\n",
    "x_new = []\n",
    "y_new = []\n",
    "prog = Progbar(target=len(x_train))\n",
    "for i in range(len(x_train)):\n",
    "    x_new += [x_train[i]] + [f(x_train[i]) for f in augment_function]\n",
    "    y_new += [y_train[i]] * (1 + len(augment_function))\n",
    "    prog.update(i)\n",
    "prog.update(len(x_train))\n",
    "x_aug = np.array(x_new)\n",
    "y_aug = np.array(y_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is critical to validate our splitting strategy.\n",
    "The algorithm must assure that the splitting process doesn't create any bias in training dataset, which can be checked by visualizing the distribution of the true dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train set:\", x_train.shape, y_train.shape)\n",
    "print(\"Valid set:\", x_valid.shape, y_valid.shape)\n",
    "print(\"Test set:\", x_test.shape, y_test.shape)\n",
    "print(\"Augmented training set:\", x_aug.shape, y_aug.shape)\n",
    "# ====== checking distribution of train, valid, test matching ====== #\n",
    "train_dist = itemfreq(y_train)\n",
    "valid_dist = itemfreq(y_valid)\n",
    "test_dist = itemfreq(y_test)\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.subplot(3, 1, 1)\n",
    "plot_hist(y_train, ax, \"Training distribution\")\n",
    "ax = plt.subplot(3, 1, 2)\n",
    "plot_hist(y_train, ax, \"Validating distribution\")\n",
    "ax = plt.subplot(3, 1, 3)\n",
    "plot_hist(y_train, ax, \"Testing distribution\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training digit classifier\n",
    "\n",
    "Most of machine learning algorithm require the labels to be one - hot encoded, which is visualized by following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== convert labels to one_hot for training ====== #\n",
    "labels = [\"Number: %d\" % i for i in y_train[:16]]\n",
    "y_train = one_hot(y_train, nb_classes=10)\n",
    "y_aug = one_hot(y_aug, nb_classes=10)\n",
    "y_test = one_hot(y_test, nb_classes=10)\n",
    "y_valid = one_hot(y_valid, nb_classes=10)\n",
    "plt.figure()\n",
    "plt.imshow(y_train[:16], cmap=plt.cm.Greys_r)\n",
    "plt.xticks(np.arange(10))\n",
    "plt.yticks(np.arange(16), labels)\n",
    "plt.suptitle(\"One-hot labels matrix\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating neural network classifier with keras\n",
    "\n",
    "The following function create a neural network, which output 10 probability values(i.e. softmax output) to represent the confident of given image for 10 different digits.\n",
    "\n",
    "The network is trained on ** (x_train, y_train)**, validated on ** (x_valid, y_valid)**, and finally evaluated using ** (x_test, y_test)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def train_and_test_dnn(x_train, y_train,\n",
    "                       x_valid, y_valid,\n",
    "                       x_test, y_test,\n",
    "                       title):\n",
    "    input_shape = x_train.shape[1:]\n",
    "    model = Sequential()\n",
    "    model.add(Reshape(target_shape=(np.prod(input_shape),),\n",
    "                      input_shape=input_shape))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "    #showing the network configuration\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=128,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_valid, y_valid))\n",
    "    # ====== plot history ====== #\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(train_loss, color='b', label='Training loss')\n",
    "    plt.plot(val_loss, color='r', label=\"Validing loss\")\n",
    "    plt.suptitle(title + \"(cross-entropy loss)\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    train_loss = history.history['acc']\n",
    "    val_loss = history.history['val_acc']\n",
    "    plt.plot(train_loss, color='b', label='Training Accuracy')\n",
    "    plt.plot(val_loss, color='r', label=\"Validing Accracy\")\n",
    "    plt.suptitle(title + \"(Accuracy)\")\n",
    "    plt.legend()\n",
    "    # ====== final evaluation ====== #\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first train the model on original MNIST training set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_dnn(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "    'MNIST Original data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model summary and learning curves are also procedure, we can use this information for diagnose the training process.\n",
    "\n",
    "Let see if the augmented dataset really help in this case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_dnn(x_aug, y_aug, x_valid, y_valid, x_test, y_test,\n",
    "    'MNIST Augmented data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why the augmented data doesn't work out?\n",
    "\n",
    "* The data is simple and there are no complicated transformations.\n",
    "* The amount of training data is significantly increased, hence, it probably require more powerful network to learn additional representation.\n",
    "\n",
    "\n",
    "## What about colored images?\n",
    "\n",
    "We use[CIFAR - 10](http: // www.cs.toronto.edu / ~kriz / cifar.html) dataset for simulating similar approach to colored images.\n",
    "\n",
    "The original CIFAR - 10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
    "\n",
    "The data in this example is 15000 randomly selected images from CIFAR - 10.\n",
    "The ten categories are:\n",
    "\n",
    "* airplane\n",
    "* automobile\n",
    "* bird\n",
    "* cat\n",
    "* deer\n",
    "* dog\n",
    "* frog\n",
    "* horse\n",
    "* ship\n",
    "* truck\n",
    "\n",
    "Load and visualize the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('CIFAR_x.npy')\n",
    "y = np.load('CIFAR_y.npy')\n",
    "print(\"CIFAR shapes:\", x.shape, y.shape)\n",
    "\n",
    "# ====== visualize the data ====== #\n",
    "fig = plt.figure()\n",
    "labels = ''\n",
    "n = int(np.sqrt(NB_OF_VISUALIZATION))\n",
    "for i in range(NB_OF_VISUALIZATION):\n",
    "    ax = plt.subplot(n, n, i + 1)\n",
    "    ax.axis('off')\n",
    "    # plot grey scale image require 2D array\n",
    "    plt.imshow(x[i])\n",
    "    ax.set_title(cifar_labels[y[i]], fontsize=10)\n",
    "\n",
    "# ====== plot differnt channel ====== #\n",
    "fig = plt.figure()\n",
    "sample_img = x[8]\n",
    "title = ['R', 'G', 'B']\n",
    "for i in range(3):\n",
    "    temp = np.zeros(sample_img.shape, dtype='uint8')\n",
    "    temp[:, :, i] = sample_img[:, :, i]\n",
    "    ax = plt.subplot(1, 3, i + 1)\n",
    "    ax.imshow(temp)\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(\"Channel: \" + title[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data preparation and splitting\n",
    "\n",
    "We repeat the same process applied for MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== again split train, test, valid ====== #\n",
    "# shuffle the data, note the order of x and y must match\n",
    "permutation = np.random.permutation(len(x))\n",
    "x = x[permutation]\n",
    "y = y[permutation]\n",
    "\n",
    "nb_train = int(TRAINING_PORTION * len(x))\n",
    "nb_valid = int(VALID_PORTION * len(x))\n",
    "nb_test = len(x) - nb_train - nb_valid\n",
    "\n",
    "x_train = x[:nb_train]\n",
    "y_train = y[:nb_train]\n",
    "\n",
    "x_valid = x[nb_train:nb_train + nb_valid]\n",
    "y_valid = y[nb_train:nb_train + nb_valid]\n",
    "\n",
    "x_test = x[nb_train + nb_valid:]\n",
    "y_test = y[nb_train + nb_valid:]\n",
    "\n",
    "# ====== augmenting the training data ====== #\n",
    "augment_function = [lambda img: shift(img, 0.1, -0.2),\n",
    "                    lambda img: rotate(img, 45)]\n",
    "# apply on out data\n",
    "x_new = []\n",
    "y_new = []\n",
    "prog = Progbar(target=len(x_train))\n",
    "for i in range(len(x_train)):\n",
    "    x_new += [x_train[i]] + [f(x_train[i]) for f in augment_function]\n",
    "    y_new += [y_train[i]] * (1 + len(augment_function))\n",
    "    prog.update(i)\n",
    "prog.update(len(x_train))\n",
    "x_aug = np.array(x_new)\n",
    "y_aug = np.array(y_new)\n",
    "\n",
    "# ====== print info ====== #\n",
    "print(\"Train set:\", x_train.shape, y_train.shape)\n",
    "print(\"Augmented set:\", x_aug.shape, y_aug.shape)\n",
    "print(\"Valid set:\", x_valid.shape, y_valid.shape)\n",
    "print(\"Test set:\", x_test.shape, y_test.shape)\n",
    "print(\"Augmented training set:\", x_aug.shape, y_aug.shape)\n",
    "\n",
    "# ====== convert labels to one_hot for training ====== #\n",
    "y_train = one_hot(y_train, nb_classes=10)\n",
    "y_aug = one_hot(y_aug, nb_classes=10)\n",
    "y_test = one_hot(y_test, nb_classes=10)\n",
    "y_valid = one_hot(y_valid, nb_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training classifier\n",
    "\n",
    "Again, we apply the same network for CIFAR dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== train FNN on CIFAR ====== #\n",
    "train_and_test_dnn(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "    \"CIFAR-DNN unnormalized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training is not converged, there is no improvement in the validation set as well as the training.\n",
    "The test accuracy is about _8%_ which is below random guess.\n",
    "So what **wrong**?\n",
    "\n",
    "### Normalizing the data\n",
    "\n",
    "It is notable that the CIFAR-10 provided features in **uint8** data type, and the intensity of each pixel is from 0 to 255.\n",
    "The big values would magnify the backpropagated gradients values, as a results, the weights are moving around so fast that they cannot reach a better solution.\n",
    "\n",
    "We normalize the values in range **[0., 1.]**. Then training the network again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== fail to converge, normalize the data ====== #\n",
    "x_train = x_train.astype('float32')\n",
    "x_train /= 255.\n",
    "x_aug = x_aug.astype('float32')\n",
    "x_aug /= 255.\n",
    "x_valid = x_valid.astype('float32')\n",
    "x_valid /= 255.\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255.\n",
    "train_and_test_dnn(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "    \"CIFAR-DNN normalized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The network converged, and we get significant improvement, but it is nothing compare to _>90%_ on MNIST dataset.\n",
    "Could we get a better model for this task?\n",
    "\n",
    "### Convolutional Neural Network for image recognition\n",
    "\n",
    "Creating convolutional neural network in keras is straight forward:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test_cnn(x_train, y_train,\n",
    "                       x_valid, y_valid,\n",
    "                       x_test, y_test,\n",
    "                       title):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                     input_shape=x_train.shape[1:],\n",
    "                     activation='relu', data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3),\n",
    "                     activation='relu', data_format='channels_last'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=RMSprop(),\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=128,\n",
    "                        epochs=5,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_valid, y_valid))\n",
    "    # ====== plot history ====== #\n",
    "    plt.figure()\n",
    "    plt.subplot(1, 2, 1)\n",
    "    train_loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    plt.plot(train_loss, color='b', label='Training loss')\n",
    "    plt.plot(val_loss, color='r', label=\"Validing loss\")\n",
    "    plt.suptitle(title + \"(cross-entropy loss)\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    train_loss = history.history['acc']\n",
    "    val_loss = history.history['val_acc']\n",
    "    plt.plot(train_loss, color='b', label='Training Accuracy')\n",
    "    plt.plot(val_loss, color='r', label=\"Validing Accracy\")\n",
    "    plt.suptitle(title + \"(Accuracy)\")\n",
    "    plt.legend()\n",
    "    # ====== final evaluation ====== #\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We again train the network on normalized CIFAR-10, but we also try it on augmented CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_cnn(x_train, y_train, x_valid, y_valid, x_test, y_test,\n",
    "    \"CIFAR-CNN normalized data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Big improvement! Note our CNN network only need half of the amount of the parameters (~400,000) compared to fully connected network (~800,000), it demonstrate the efficiency of this network in learning image presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_test_cnn(x_aug, y_aug, x_valid, y_valid, x_test, y_test,\n",
    "    \"CIFAR_CNN augmented data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Event bigger improvement! Augmentation really work in this case"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}
